Below is an example of an R code chunk which can be executed from within the R Notebook. You can do this by clicking the green triangle to the top right of the chunk area within the Notebook. If you wanted to run all the code up until, and including, this code chunk you can click the grey triangle with the green bar [^1].

[^1]: In this case there is no previous code so it would make no difference but often RMarkdown contains multiple code chunks.


#install packages 

pacman::p_load(pacman,modeest,ggplot2)

```{r}
# This is an R code chunk
print("Hello cruel world")
```

So now you can handle the RMarkdown basics.  Let's move onto R.


# 2. Exploring the use of R using R {#WS2}

## 2.1 Demand for R programmers

How useful are R skills and tools? An [analysis](https://towardsdatascience.com/what-are-the-in-demand-skills-for-data-scientists-in-2020-a060b7f31b11) of 2681 data scientist job postings from 8 North American cities on January 25th, 2020 indicated the top 10 tools required by the employers are:

    Python (62%)
    SQL (40%)
    R (39%)
    Spark (21%)
    Cloud (20%)
    Amazon Web Services (20%)
    Java (19%)
    Tensorflow (16%)
    Hadoop (15%)
    SAS (13%)

The data was collected by analysing online job adverts for data scientists on the Indeed website in North America. Note that Tools is a categorical and multi-valued attribute of a job listing, i.e., one listing could have zero or more tool categories associated, thus the percentages do not sum to 100%. NB 14% of the sampled job listings are excluded (since it is stated that only 86% of adverts identified skills or tools).

**Exercise 2.1:** It's important to look at the data critically, though we must accept nothing is certain or perfect! What questions or concerns might you have?

Since we're thinking about data and data analysis, it would be helpful to visualise the data. Unfortunately, we don't have access to the raw data so we will need to reproduce it. Therefore I have 'scraped' some of the data from their article and plugged this into R (see below). Don't worry about the coding details for the present although be aware that for reasons of simplicity I'm just using Base R for the graphics (functions like `pie()` and `barplot()`). Later we will introduce the {ggplot2}[^3] package which will enable almost complete control and flexibility in producing beautiful data visualisations, however, if you are already a confident R programmer feel free to jump ahead.

```{r}
#Reproduce the data from the January 2020 required tools for Data Scientists

percent <- c(62,40,39,21,20,20,19,16,15,13)
skills <- c("Python","SQL","R","Spark","Cloud","AWS","Java","TensorFlow","Hadoop","SAS")

#Generate the pie chart

pie(percent, main = "Pie chart for most in demand language for machine learning", labels = skills, clockwise = TRUE)
?pie
```
```{r}
# NB we have already reproduced the data: percent and skill come from the 
# previous piechart chunk

# Generate a bar chart

barplot(percent, 
        main = "Bar chart of in-demand Data Scientist tools (Jan 2020)",
        sub = "Source: https://j.mp/2Ga8CD1", 
        ylab = "Percentage of listings that mention tool", 
        names.arg = skills,
        cex.names = 0.7,   # shrinks text size so fits on x-axis
        col="darkolivegreen", 
        density = c(100, 50, 100, 50, 50, 50, 50, 50, 50, 50))
```
In the previous task you may well have largely relied on the provided R code. Now we move onto learning about basic R syntax and some coding exercises for you to undertake.

Suppose I'm trying to calculate how much money I'm going to make from my *Modern Data* book. There are several different things I will need to store:

-   `sales` how many copies I'll sell `sales`\
-   `price` the price per copy
-   `numberStudents` number of students in the class (assume I sell one copy per student)
-   `recommend` the proportion of students so impressed that they recommend the book to friends and family
-   `income` the income generated

Let's turn this into R.

```{r}
#Compute income from sales of Ama's book

price <- 10 
numOfStudents <- 100
recommend <- 0.5

sales <- numOfStudents * (1 + recommend)
income <- sales * price
paste("Ama would earn", income)
```
Although we could just output `income`, I have added some text to make the output of the code easier to interpret with the `paste()` function to combine a character string literal delimited by quotation marks and the calculated income.

**Exercise 3.1:** Change the number of students to 200 and the recommendation rate to 0.2. What's my new estimated income?

**Exercise 3.2:** Update the sales income R code to handle tax. Assume that income is taxed at a flat rate of 20%. Modify the above R code to output gross income and net (after tax) income. Using RStudio you can edit this Week 1 Worksheet Notebook.

```{r}
numOfStudents <- 200

recommend <- 0.2

income <- numOfStudents * (1 + recommend)
print(income)

grossIncome <- income

netIncome <- grossIncome * (1 - 0.2)

print(netIncome)
```
HINT: I recommend you define a new numeric variable to store the tax rate and another for net income. For clarity you might want to rename `income` to make it obvious that it stores gross income.

**Extension Exercise 3.3:** How would you answer the question: it's possible to write a much shorter R program without any extra variables, so why bother?

It's very *important* to get into the habit of writing easy to follow R code. For this reason I have added comments and tried to select meaningful variable names.

## 3.2 Using vectors

Recall that at a Vector is a repeated group of the **same** data type, e.g., a vector of character strings.

```{r}
#Define a new vector

greetings <- c("Hi!", "Hello", "Good morning", "Saludo", "Hej")
greetings 

```
We can also check the type of `greetings`

```{r}
is.vector(greetings)
```

**Exercise 3.4:** Check the type of the variable `price` (from Section 3.1). What output do you expect?

To fully exploit the power of vectors we can access subsets of elements. To do this we use the square bracket notation `[<n>]` where $n$ is the position of the required vector element.


```{r}
#Different ways to index vector elements
greetings[2]

n <- 3

greetings[n]
greetings[1:n]
```

Notice in the above R chunk, that we can access more than one element at a time by using the `:` operator to return a range of elements. The range can be specified by literals as in `[1:3]` or integer[^4] variables e.g., `[m:n]`.

[^4]: If the index variables are not integers R will do its best to coerce the values to integers.

## 3.3 Using data frames

Data frames are amongst the most useful of the different data structures. These are two dimensional and unlike 2-dimensional matrices can comprise different constituent data types.

Let's start by examining a built-in data set mt-cars that stores information about motor cars from the 1970s that is stored as a data frame.

**Exercise 3.5:** How many variables and observations does `df` have? HINT: There are functions `nrow()` and `ncol()` if you can't be bothered to count.

You can use the `$` operator to specify a column/variable from a data frame, for instance:

Let's start by examining a built-in data set mt-cars that stores information about motor cars from the 1970s that is stored as a data frame.

```{r}
# Assign the built in data object mtcars to a new data frame df
df <- mtcars

# View the data frame in a new window in RStudio
View(df)
```

**Exercise 3.5:** How many variables and observations does `df` have? HINT: There are functions `nrow()` and `ncol()` if you can't be bothered to count.

You can use the `$` operator to specify a column/variable from a data frame, for instance:

```{r}
# Display the observations for cylinder numbers from df
df$cyl

# Apply the median function
median(df$cyl)
```
**Exercise 3.6:** Using the `$` operator determine the mean and minimum mpg for cars in df.

**Exercise 3.7:** Update the number of gears for the Mazda RX4 from 4 to 6. HINT: `mt$gear` is a vector so you can use an index to reference a particular element.

So we can use the dollar operator to identify columns/variables. What about rows/observations? There are several ways to achieve this. Using indices via the `[ ]` notation notice that since a data frame has two dimensions two arguments are needed, but since we want the entire row we can leave the argument after the comma blank.

```{r}
# To retrieve the 2nd row we could have.
df[2,]
```

**Exercise 3.8:** Modify the above code to retrieve columns 1-3. HINT: remember the `:` operators from when we were manipulating vectors.

The other way to retrieve specific observations is when the rows have names e.g., "Mazda RX4", as in this case.

```{r}
# Retrieve the observation named "Valiant"
df["Valiant",]
```
**Exercise 3.9:** Change the number of cylinders for the Valiant to 12.

```{r}
df["Valiant",2] <- 18

df["Valiant",]
```

# 4. Describing Data{#WS4} 

## 4.1 Measures of location

Let's see how to use R to compute the measures of location (mean, median, and mode) and spread (range, inter quartile range, standard deviation and variance):

We are using a small vector of numeric data

```{r}
data_vector <-c(4,7,2,5,6,2)
```

### Mean

```{r}
mean(data_vector)
```


```{r}
median(data_vector)
```

### Mode

Unlike the mean and the median there is *no* built in R function to compute the mode.  There are many ways of implementing our own mode function.  As a hint consider turning the vector into a table of frequencies that can then be sorted in decreasing order.  You can see our solution [here](#Ans4.1) in the Appendix.

```{r}
summary(data_vector)
```
```{r}
# Define a new function called mode
mode <- function(v) {
# calculate mode
# Just some dummy code you need to update as the answer is probably
# not 42 (just saying!)
return(42)
}

# Apply the function to our vector
mode(data_vector)
```

Alternatively, more easily, we can install an R package {modeest} that contains a mode function.

```{r}
library(modeest)
mfv(data_vector, method="mfv") #mfv stands for Most Frequent Value aka mode
```

### Weighted Mean

The weighted arithmetic mean is similar to an ordinary arithmetic mean (the most common type of average), except that instead of each of the data points contributing equally to the final average, some data points contribute more than others. The notion of weighted mean plays a role in descriptive statistics and also occurs in a more general form in several other areas of mathematics.

You can see the code below that uses the weighted mean function.

```{r}
grade.point <- c(17, 18, 16)
credit <- c(15,15,30)

weighted.mean(grade.point,credit)
```

## 4.2 Measures of variation

### Range 

Range --> Minimum and the maximum value

```{r}
range(data_vector)
```

### Interquartile range (IQR)

IQR: 25th and 75th percentile values
```{r}
IQR(data_vector)
```

This is based on the 25th and 75th percentile, which can also be computed in R using the quantile function:

```{r}
quantile(data_vector,c(0.25,0.75))
```

### Standard Deviation
```{r}
sd(data_vector)
```

#variance
```{r}
var(data_vector)
```

# 5. Exploring Data{#WS5}

In this part of the lab session the key objectives are to use R through RStudio to read in a small set of data and to explore the data. In R, it is possible to read data from different file formats:

 * manual input
 * plain text
 * delimited text - such as .csv/.tsv files
 * spreadsheets
 * SAS formats 
 
 ## Reding in a csv file

So far we have made use of data that is already in R or input our own. In practice often data will be provided in .csv fomat and R makes it easy to read it in.

 * Save a copy of that data in the same directory where you have saved this .Rmd file you are currently going through
 *read data from worm:
 
```{r}
worm <- read.csv("worms.csv")
```

If you want to check what the data looks like:
```{r}
head(worm, n=10)
```
Now lets see how to do some descriptive data analysis. 

## Numerical summaries of categorical variables

```{r}
table(worm$Damp, worm$Vegetation)
```

 Play around with table - you can also do a table summary for one variable at a time.

There are many additional packages that offer more sophisticated options. We will explore relevant ones later in the module. It is also possible to do frequency tables for more than one column at the same time (in effect creating a contingency table):

## Graphical summaries for categorical variables

Now let's look at ways of graphically summarising a column of categorical data from our data frame. Let's start with the vegetation, using the basic R library

```{r}
table(worm$Vegetation)
barplot(table(worm$Vegetation))
```
It is also possible to use the same syntax for the two way table (contingency table)
```{r}
hist(worm$Soil.pH)
```

### Using ggplot2 (Optional)

One library that is very handy for graphs is the {ggplot2}. 

Before using a library you need to install it (first time) and load it. As the ggplot2 library is installed then you only need to load it:

```{r}
library(ggplot2)
```

There are a huge number of options in {ggplot2}. In most cases you start with `ggplot()`, supply a dataset and aesthetic mapping (with `aes()`). You then add on layers (like `geom_point()` or `geom_histogram()`), scales (like `scale_colour_brewer()`), faceting specifications (like `facet_wrap()`) and coordinate systems (like `coord_flip()`).

```{r}
head(worm)
ggplot(data = worm)+geom_point(aes(x=Area,y=Soil.pH))
ggplot(worm)+geom_bar(aes(x=Damp),fill="blue")
```
There is a lot you can specify in ggplot - see below for another example which now has well labelled titles and axis and a different theme.

```{r}
ggplot(worm) + geom_bar(aes(x=Vegetation), fill="blue") + labs(title="Vegetation from the Worms data") + scale_y_continuous(name="Frequency", breaks=c(0,5,10)) + theme_classic()
```

### Pie chart

The code chunk below creates a pie chart. In order to do such a plot, the frequency table needs to be computed first, then transformed into a data frame, before finally being plotted using a ggplot option (coord_polar).

Note that giving clear column names makes it easier and quicker to get a better labelled graph.

```{r}
w1 <-table(worm$Vegetation)
w2 <- as.data.frame(w1)
#w2

colnames(w2) <- c("Vegetation", "Frequency")
ggplot(w2, aes(x="", y=Frequency, fill=Vegetation))+geom_bar(width=1, stat = "identity") +coord_polar("y", start = 0) +labs(title="Pie Chart for the Vegeation from the Worms data")
```

### Graphical summaries for numerical variables

#### Histogram

A histogram to see the distribution of the values for one of the continuous columns can be created in many ways. 
Using the base R code:

```{r}
hist(worm$Worm.density, xlab = "Density",ylab = "Count",main="Distribution of Density")
```

OR ggplot n also be used

```{r}
ggplot(worm, aes(x=Worm.density)) +
  geom_histogram(fill="blue") +
  labs(title="Histogram of Worm Density") +
  scale_x_continuous(name="Worm Density", breaks = c(0,1,2,3,4,5,6,7,8,9)) +
  theme_bw()

```

#### Box plot

Another interesting perspective on a continuous variable, when it is part of a data set with categorical variable is to look at them both at the same time. A **boxplot** is a useful tool to achieve this.

Using R Base:

```{r}
boxplot(worm$Worm.density~worm$Damp)
```

or using ggplot 
```{r}
#box plot
ggplot(worm, aes(x=Worm.density, y=Damp)) +
  geom_boxplot(fill="steelblue2") +
  theme_classic() +
  labs(title="Box Plot of Worm Density by Damp") +
  coord_flip()
```

# 6. The diamonds dataset casestudy {#WS6}

Now over to you!

Have a go at performing a descriptive analysis of a data set. In order to do this we are going to make use of the *diamonds* data set that is available in R. 

This data set is available in the *{ggplot}* library that was already loaded earlier in this session.

(a) Run the code below to see the description of the diamond data and its contents.


```{r}
help("diamonds")
```

(b) Check that the data set *diamonds* does indeed contain the columns as in the help
```{r}
names(diamonds)
```
or to have more details on the columns:
```{r}
str(diamonds)
```


(c) The help description of the data set has the ranges for the variables in this data set. Check that this is the case in the data. 
Are there any variables out of range?

The ranges for the numerical variables can be obtained using the summary function. There are other ways.

To run summary on one variable only use the \$ to specify the column.

```{r}
summary(diamonds$price)
```


The code above can be repeated for each of the variables in turn or use summary on all the data frame.
```{r}
summary("diamonds")
```

(d) How many levels (or different categories) are in the column labelled *cut*? 
```{r}

```

It seems like there is an inconsistency in column z, the table shows a range of 0-3.18 but the actual data tells a different story. *Always check what is in the data*

(d) How many levels (or different categories) are in the column labelled *cut*? 

The levels of a categorical variable can be obtained using a table function.
```{r}
table(diamonds$cut)
```

The variable cut is categorical and has 5 levels or values.

(e) Generate a numerical summary for each variable in the data set - take care to use the appropriate technique for each different variable type.

The numerical summary can be done as in (c), but in general for numerical attributes a summary works well, a table for categorical variables.

```{r}
summary(diamonds)
```

(f) For each variable generate a plot, use different options and make sure the plots are labelled, and suitable to the type of variable.

For example for a numerical attribute we would look at a histogram

Firstly we can use the graph function in base R (this does not need a separate library)
```{r}
hist(diamonds$price, main = paste("Histogram of price"), xlab="Price")
```
(optional) another way to plot this can be achieved using ggplot library:
```{r}
ggplot(diamonds, aes(x=price)) + geom_histogram(binwidth = 10) +theme_classic() + ggtitle("Histogram of the Diamond Price")
```

The same code can be used for the remaining continuous variables.

For the categorical variables we can use this shortcut that uses a table function to then make a plot.
```{r}
barplot(table(diamonds$cut), xlab = "Cut", ylab = "Frequency", main="Bar chart of the Frequency of each Diamond cut")
```
The same code can be used for the remaining continuous variables.

For the categorical variables we can use this shortcut that uses a table function to then make a plot.
```{r}
barplot(table(diamonds$cut), xlab = "Cut",ylab = "Frequency", main="Bar chart of the Frequency of each Diamond cut")
```

(Optional) If we want to use the GGplot library then the following ggplot syntax can be used:
```{r}
ggplot(diamonds, aes(cut)) + geom_bar() + ggtitle("Frequency f different cuts") + theme_classic()
```
Other options include pie charts.

(g) Explore the graphing of one categorical against one of the continuous variables in this data.

This is a good opportunity to use a box plot.
```{r}
boxplot(diamonds$price~diamonds$cut, xlab ="Cut", ylab = "Price ")
```
```{r}
ggplot(diamonds,aes(x=cut,y=price)) + geom_boxplot() + theme_classic() + ggtitle("Price vs Cut of Diamonds")
```
You can try the same changing the variable on the y axis.
